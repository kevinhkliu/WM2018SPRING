{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read NTUSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of postive word: 2647\n",
      "number of negative word: 7740\n"
     ]
    }
   ],
   "source": [
    "neg_dict = {}\n",
    "with open(\"chinese_sentiment/dict/ntusd-negative.txt\") as f:\n",
    "    lines = [line.strip() for line in f.readlines()]\n",
    "    for word in lines:\n",
    "        neg_dict[word] = 1\n",
    "neg_dict.pop('', None)\n",
    "post_dict = {}        \n",
    "with open(\"chinese_sentiment/dict/ntusd-positive.txt\") as f:\n",
    "    lines = [line.strip() for line in f.readlines()]    \n",
    "    for word in lines:\n",
    "        post_dict[word] = 1\n",
    "print('number of postive word: ' + str(len(post_dict)))\n",
    "print('number of negative word: ' + str(len(neg_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read ANTUSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANTUSD = {}\n",
    "with open(\"chinese_sentiment/ANTUSD/opinion_word_utf8.csv\", encoding='utf-8') as f:\n",
    "    lines = [line.strip() for line in f.readlines()]\n",
    "for line in lines:\n",
    "    word = line.split(',')[0]\n",
    "    score = line.split(',')[1]\n",
    "    ANTUSD[word] = float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.55"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANTUSD['低吼']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27221"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ANTUSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label_comment():\n",
    "    index = []\n",
    "    label = []\n",
    "    comment = []\n",
    "    for idx, line in enumerate(open('data/semi_comment.csv', 'r', encoding='UTF-8')):\n",
    "        list = line.split('_+_')\n",
    "        if len(list) >= 2:\n",
    "            if list[1] == '1\\n' or list[1] == '-1\\n':\n",
    "                comment.append(list[0])\n",
    "                label.append(int(list[1].strip('\\n')))\n",
    "\n",
    "    return comment, np.array(label)\n",
    "test_comment, test_label = read_label_comment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANTUSD approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANTUSD_approach(list_):\n",
    "    ANTUSD_sentiment_list = []\n",
    "    ANTUSD_post_token = []\n",
    "    ANTUSD_neg_token = []\n",
    "    for sentence in list_:\n",
    "        score = 0\n",
    "        temp_post = []\n",
    "        temp_neg = []\n",
    "        for token in sentence.split(' '):\n",
    "            if token in ANTUSD:\n",
    "                score = score + ANTUSD[token]\n",
    "                if ANTUSD[token] >= 0:\n",
    "                    temp_post.append(token)\n",
    "                else:\n",
    "                    temp_neg.append(token)\n",
    "        ANTUSD_post_token.append(temp_post)\n",
    "        ANTUSD_neg_token.append(temp_neg)\n",
    "        if score >= 0:\n",
    "            ANTUSD_sentiment_list.append(1)\n",
    "        else:\n",
    "            ANTUSD_sentiment_list.append(-1)\n",
    "    return ANTUSD_sentiment_list, ANTUSD_post_token, ANTUSD_neg_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NTUSD approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NTUSD_sentiment_list = []\n",
    "NTUSD_post_token = []\n",
    "NTUSD_neg_token = []\n",
    "for sentence in test_comment:\n",
    "    post_score = 0\n",
    "    neg_score = 0\n",
    "    temp_post = []\n",
    "    temp_neg = []\n",
    "    for token in sentence.split(' '):\n",
    "        if token in post_dict:\n",
    "            post_score = post_score + 1\n",
    "            temp_post.append(token)\n",
    "        elif token in neg_dict:\n",
    "            neg_score = neg_score + 1\n",
    "            temp_neg.append(token)\n",
    "    NTUSD_post_token.append(temp_post)\n",
    "    NTUSD_neg_token.append(temp_neg)\n",
    "    if post_score >= neg_score:\n",
    "        NTUSD_sentiment_list.append(1)\n",
    "    else:\n",
    "        NTUSD_sentiment_list.append(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Testing result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTUSD accuracy: 0.6835443037974683\n",
      "NTUSD accuracy: 0.6784810126582278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ANTUSD_sentiment_list, ANTUSD_post_token, ANTUSD_neg_token = ANTUSD_approach(test_comment)\n",
    "print(\"ANTUSD accuracy:\",accuracy_score(ANTUSD_sentiment_list, test_label))\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(\"NTUSD accuracy:\",accuracy_score(NTUSD_sentiment_list, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment: \n",
      "全「台」稱讚齊鼓掌，峽「灣」風雲起濤浪，匯「總」首善發光芒，一「統」江山震四方，南「柯」有夢志飛揚，棄「文」從政展擔當，儒「哲」挺身振家邦，美「好」典範垂飄香。.柯P：出來選2020的總統啦。\n",
      "\n",
      "Gold sentiment: 1\n",
      "NTUSD sentiment: 1\n",
      "ANTUSD sentiment: 1\n",
      "\n",
      "post_token: \n",
      "['稱讚', '鼓掌', '發光', '江山', '擔當', '挺身', '典範']\n",
      "['稱讚', '鼓掌']\n",
      "\n",
      "neg_token: \n",
      "[]\n",
      "[]\n",
      "-----------------------------------------------------------------------------------\n",
      "comment: \n",
      "全「台」稱讚齊鼓掌，峽「灣」風雲起濤浪，匯「總」首善發光芒，一「統」江山震四方，南「柯」有夢志飛揚，棄「文」從政展擔當，儒「哲」挺身振家邦，美「好」典範垂飄香。.柯P：出來選2020的總統啦。\n",
      "\n",
      "Gold sentiment: 1\n",
      "NTUSD sentiment: 1\n",
      "ANTUSD sentiment: 1\n",
      "\n",
      "post_token: \n",
      "['稱讚', '鼓掌', '發光', '江山', '擔當', '挺身', '典範']\n",
      "['稱讚', '鼓掌']\n",
      "\n",
      "neg_token: \n",
      "[]\n",
      "[]\n",
      "-----------------------------------------------------------------------------------\n",
      "comment: \n",
      "一堆政客只會出張嘴在那邊看世大運搞砸，好像不是他們黨執政的縣市，辦啥活動都只會靠北。\n",
      "\n",
      "Gold sentiment: -1\n",
      "NTUSD sentiment: -1\n",
      "ANTUSD sentiment: -1\n",
      "\n",
      "post_token: \n",
      "['好像']\n",
      "[]\n",
      "\n",
      "neg_token: \n",
      "['政客', '搞砸', '不是', '靠北']\n",
      "['不是', '靠北']\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0,3):\n",
    "    print('comment: ')\n",
    "    print(test_comment[idx].replace(' ', ''))\n",
    "    print( )\n",
    "    print('Gold sentiment: ' + str(test_label[idx]))\n",
    "    print('NTUSD sentiment: ' + str(NTUSD_sentiment_list[idx]))\n",
    "    print('ANTUSD sentiment: ' + str(ANTUSD_sentiment_list[idx]))\n",
    "    print()\n",
    "    print('post_token: ')\n",
    "    print(ANTUSD_post_token[idx])\n",
    "    print(NTUSD_post_token[idx])\n",
    "    print( )\n",
    "    print('neg_token: ')\n",
    "    print(ANTUSD_neg_token[idx])\n",
    "    print(NTUSD_neg_token[idx])\n",
    "    print('-----------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kp and yao comments prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "(tf_kp_posts,tf_kp_posts_feature_names, kp_sum_posts_clean_seg, tf_kp_comments,tf_kp_comments_feature_names, kp_sum_comments_clean_seg) = joblib.load( \"result/tf_idf_kp_all.pkl\" )\n",
    "(tf_yao_posts,tf_yao_posts_feature_names, yao_sum_posts_clean_seg, tf_yao_comments,tf_yao_comments_feature_names, yao_sum_comments_clean_seg) = joblib.load( \"result/tf_idf_yao_all.pkl\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of kp posts: 1526\n",
      "# of kp posts time: 1526\n",
      "# of kp comments: 74705\n",
      "# of kp comments time: 74705\n",
      "# of kp comments to index: 74705\n",
      "\n",
      "# of yao posts: 977\n",
      "# of yao posts time: 977\n",
      "# of yao comments: 15497\n",
      "# of yao comments time: 15497\n",
      "# of yao comments to index: 15497\n"
     ]
    }
   ],
   "source": [
    "print('# of kp posts: ' + str(len(kp_sum_posts)))\n",
    "print('# of kp posts time: ' + str(len(kp_posts_time)))\n",
    "print('# of kp comments: ' + str(len(kp_sum_comments)))\n",
    "print('# of kp comments time: ' + str(len(kp_comments_time)))\n",
    "print('# of kp comments to index: ' + str(len(kp_comments_to_post_index)))\n",
    "print()\n",
    "print('# of yao posts: ' + str(len(yao_sum_posts)))\n",
    "print('# of yao posts time: ' + str(len(yao_posts_time)))\n",
    "print('# of yao comments: ' + str(len(yao_sum_comments)))\n",
    "print('# of yao comments time: ' + str(len(yao_comments_time)))\n",
    "print('# of yao comments to index: ' + str(len(yao_comments_to_post_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_comments_label, ANTUSD_post_token_kp,  ANTUSD_neg_token_kp= ANTUSD_approach(kp_sum_comments_clean_seg)\n",
    "yao_comments_label, ANTUSD_post_token_yao,  ANTUSD_neg_token_yao= ANTUSD_approach(yao_sum_comments_clean_seg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kp post: 0\n",
      "還在當醫師的時候，我寫了第一本書「白色的力量」，講了很多對當時社會的批判，以及從醫多年累積的生死觀，算是我行醫二十幾年下來的回顧之作。這本書，等等凌晨0點在全台各大電子書店就會開始預購，除了宣揚理念，順便賺點版稅貼補家用，大家就多多捧場一下。第二、第三本則是跟選舉有關，一本在選前談從政的心境，一本是選後回顧團隊的SOP。---「光榮城市」新書預購資訊（22日0時正式預購）http://pcse.pw/7WLYS「光榮城市」簽書會活動資訊http://pcse.pw/79QBY新書首發讀者見面會時間：6/30（六）PM 6:00地點：台北捷運中山站第二廣場（R7光盒旁）。現在，我每天七點半準時上工，不知不覺也進入第四年任期，反省改進是我每日的功課，我每天都會想很多事情如果重來一遍，怎麼做會比較好，想著想著，乾脆就記錄下來，除了市政上的理念，當然還有很多當市長之後學到的寶貴經驗。不包括醫學書籍的話，「光榮城市」是我寫的第四本書。不只是寫，我還自己做投影片解說，講了5個小時，出版社乾脆直接錄下來燒錄成兩片DVD，幕僚都笑說大家睡不著的時候可以拿來看。\n",
      "\n",
      "kp posts time: \n",
      "2018-06-21T12:39:10+0000\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "kp comments: \n",
      "恭喜你變成大作家，不讓你專美於前，我也要開始寫作，等你出完這本書，明年換我出，呵呵呵，咱們倆接力賺稿費，支付不足的選舉經費和我們官司的錢。\n",
      "\n",
      "kp comments time: \n",
      "2018-06-21T12:53:45+0000\n",
      "\n",
      "kp comments to post: \n",
      "0\n",
      "\n",
      "kp sentiments labels: \n",
      "1\n",
      "\n",
      "kp postive token: \n",
      "['恭喜', '變成', '作家', '專美於前', '開始', '呵呵', '支付']\n",
      "\n",
      "kp negative token: \n",
      "['不足']\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "kp comments: \n",
      "柯P您好，如果之後您有製作影片的需求，但是缺少人力和經費的話，到選舉結束前我都願意免費協助您製作各種動畫、剪輯和簡單的文案。本人在業界雖然不是什麼大導演，但也有8年的相關經驗，雖然沒有錢，但我願意出這份心力來贊助您。#台中柯粉#網路義勇軍。\n",
      "\n",
      "kp comments time: \n",
      "2018-06-21T13:09:07+0000\n",
      "\n",
      "kp comments to post: \n",
      "0\n",
      "\n",
      "kp sentiments labels: \n",
      "1\n",
      "\n",
      "kp postive token: \n",
      "['需求', '結束', '願意', '免費', '協助', '簡單', '相關', '經驗', '願意', '贊助']\n",
      "\n",
      "kp negative token: \n",
      "['缺少', '不是', '沒有']\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "kp comments: \n",
      "把花國家的錢當做在花自己的錢那樣小心翼翼，這是市長主政對台灣政治風氣最大的改變之一。【我在花市政府的錢當做在花自己的錢，不是說國家的錢就不是錢】【大家都沒有把國家的錢當錢，每個都在負債，我非常討厭這一點】柯市長無論對於花錢和還債，都是慎而再慎，為什麼啊。因為這是國家的錢啊。\n",
      "\n",
      "kp comments time: \n",
      "2018-06-21T12:42:26+0000\n",
      "\n",
      "kp comments to post: \n",
      "0\n",
      "\n",
      "kp sentiments labels: \n",
      "-1\n",
      "\n",
      "kp postive token: \n",
      "['當做', '自己', '那樣', '最大', '改變', '當做', '自己', '非常']\n",
      "\n",
      "kp negative token: \n",
      "['不是', '沒有', '負債', '討厭', '無論', '還債']\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "kp comments: \n",
      "看到這新書預告，聽到音樂就有點想哭。我是住法國的柯粉，從市長選舉時就每天看當天youtube 柯p的影片，所有演講都聽到滾瓜爛熟，沒有一天中斷。去年暑假回台看世大運，希望八月底誠品那場能搶到簽名握手的機會，更希望11月底可以想辦法拋夫棄子回台投票。\n",
      "\n",
      "kp comments time: \n",
      "2018-06-21T13:37:16+0000\n",
      "\n",
      "kp comments to post: \n",
      "0\n",
      "\n",
      "kp sentiments labels: \n",
      "1\n",
      "\n",
      "kp postive token: \n",
      "['看到', '音樂', '所有', '希望', '搶到', '機會', '希望', '可以']\n",
      "\n",
      "kp negative token: \n",
      "['沒有', '中斷']\n",
      "\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print('kp post: ' + str(idx))\n",
    "print(kp_sum_posts[idx])\n",
    "print()\n",
    "print('kp posts time: ')\n",
    "print(kp_posts_time[idx])\n",
    "print()\n",
    "for comments_idx in range(1,5):\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('kp comments: ')\n",
    "    print(kp_sum_comments[comments_idx])\n",
    "    print()\n",
    "    print('kp comments time: ')\n",
    "    print(kp_comments_time[comments_idx])\n",
    "    print()\n",
    "    print('kp comments to post: ')  # 記錄這則留言是哪篇貼文的留言\n",
    "    print(kp_comments_to_post_index[comments_idx])\n",
    "    print()\n",
    "    print('kp sentiments labels: ')\n",
    "    print(kp_comments_label[comments_idx])\n",
    "    print()\n",
    "    print('kp postive token: ')\n",
    "    print(ANTUSD_post_token_kp[comments_idx])\n",
    "    print()\n",
    "    print('kp negative token: ')\n",
    "    print(ANTUSD_neg_token_kp[comments_idx])\n",
    "    print()\n",
    "print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60584\n",
      "74705\n",
      "13028\n",
      "15497\n"
     ]
    }
   ],
   "source": [
    "print(len([label for label in kp_comments_label if label == 1]))\n",
    "print(len(kp_comments_label))\n",
    "print(len([label for label in yao_comments_label if label == 1]))\n",
    "print(len(yao_comments_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
